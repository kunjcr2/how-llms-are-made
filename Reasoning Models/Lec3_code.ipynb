{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers accelerate torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306084d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- simple \"stepwise\" reward using a final-answer reward model ---\n",
    "def reward_step_score(prompt, text, rw, rw_tok, device=\"cuda\"):\n",
    "    sents = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text.strip()) if s.strip()]\n",
    "    if not sents:\n",
    "        return 0.0\n",
    "    pref = prompt.strip() + \"\\n\"\n",
    "    scores = []\n",
    "    for i in range(1, len(sents) + 1):\n",
    "        part = pref + \" \".join(sents[:i])\n",
    "        inp = rw_tok(part, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            v = rw(**inp).logits[0].item()\n",
    "        scores.append(float(v))\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b23105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- tiny helpers (short names) ---\n",
    "def chat(p):  # adjust to your chat template if needed\n",
    "    return f\"<|system|>\\nYou are a helpful assistant.\\n<|user|>\\n{p}\\n<|assistant|>\\n\"\n",
    "\n",
    "def gen(lm, lm_tok, prefix, k, device=\"cuda\", max_new_tokens=96):\n",
    "    inp = lm_tok(prefix, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = lm.generate(\n",
    "            **inp,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=k,\n",
    "            pad_token_id=lm_tok.eos_token_id,\n",
    "        )\n",
    "    return [lm_tok.decode(o, skip_special_tokens=True) for o in out]\n",
    "\n",
    "def cont(parent, child):\n",
    "    return child[len(parent):].strip() if child.startswith(parent) else child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- basic beam search with reward-only ranking ---\n",
    "def beam_search_reward(prompt, lm, lm_tok, rw, rw_tok,\n",
    "                       N=4, M=2, rounds=2, max_new_tokens=96, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    N = total kept per round, M = parents to expand (N % M == 0),\n",
    "    rounds = how many expansions. Ranking = reward only.\n",
    "    \"\"\"\n",
    "    assert N % M == 0, \"N must be divisible by M\"\n",
    "    lm.to(device).eval()\n",
    "    rw.to(device).eval()\n",
    "\n",
    "    px = chat(prompt)\n",
    "\n",
    "    # round 0\n",
    "    init = gen(lm, lm_tok, px, N, device, max_new_tokens)\n",
    "    beams = []\n",
    "    for full in init:\n",
    "        comp = cont(px, full)\n",
    "        sc = reward_step_score(prompt, comp, rw, rw_tok, device)\n",
    "        beams.append({\"full\": full, \"comp\": comp, \"score\": sc})\n",
    "\n",
    "    # expand rounds\n",
    "    for _ in range(rounds):\n",
    "        parents = sorted(beams, key=lambda b: b[\"score\"], reverse=True)[:M]\n",
    "        kids = []\n",
    "        K = N // M\n",
    "        for p in parents:\n",
    "            child_full_list = gen(lm, lm_tok, p[\"full\"], K, device, max_new_tokens)\n",
    "            for cf in child_full_list:\n",
    "                comp = cont(px, cf)\n",
    "                sc = reward_step_score(prompt, comp, rw, rw_tok, device)\n",
    "                kids.append({\"full\": cf, \"comp\": comp, \"score\": sc})\n",
    "        beams = sorted(kids, key=lambda b: b[\"score\"], reverse=True)[:N]\n",
    "\n",
    "    # return best-first\n",
    "    return sorted(beams, key=lambda b: b[\"score\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a11060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- example (swap models if you like) ---\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    lm_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "    rw_name = \"OpenAssistant/reward-model-deberta-v3-large-v2\"\n",
    "\n",
    "    lm_tok = AutoTokenizer.from_pretrained(lm_name, use_fast=True)\n",
    "    lm = AutoModelForCausalLM.from_pretrained(\n",
    "        lm_name,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else None,\n",
    "        device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    )\n",
    "\n",
    "    rw_tok = AutoTokenizer.from_pretrained(rw_name, use_fast=True)\n",
    "    rw = AutoModelForSequenceClassification.from_pretrained(\n",
    "        rw_name,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else None,\n",
    "        device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    )\n",
    "\n",
    "    prompt = \"Roger has five tennis balls and buys two cans of three tennis balls each. How many tennis balls does he have now? Think step by step.\"\n",
    "    res = beam_search_reward(prompt, lm, lm_tok, rw, rw_tok, N=4, M=2, rounds=2, device=device)\n",
    "    for i, r in enumerate(res[:3], 1):\n",
    "        print(f\"[{i}] score={r['score']:.3f}  {r['comp'][:160].replace('\\\\n', ' ')}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
