# ğŸšª Gated Linear Units (GLUs) in Modern Models

GLUs are like **smart doors** ğŸ›‘ğŸšª that decide **how much information passes through** in a neural network.
Instead of pushing every token through heavy computation, GLUs decide:

* âœ… which tokens go deep,
* âŒ which ones can skip,
* ğŸ”„ how much of each token to keep.

---

## ğŸ”‘ Intuition

* Split the input into two parts:

  * **A = information**
  * **B = gate (decision maker)**
* Formula:

  $$
  GLU(X) = A \odot \sigma(B)
  $$

  where `Ïƒ` is a sigmoid (makes values between 0 and 1).

So:

* If gate â‰ˆ 1 â†’ let token info pass.
* If gate â‰ˆ 0 â†’ block token info.
* If gate â‰ˆ 0.5 â†’ pass half.

---

## ğŸ–¼ï¸ Token Flow with GLU (Mermaid Diagram)

```mermaid
flowchart LR
    A[Token Input] --> B[Linear Transform â†’ A]
    A --> C[Linear Transform â†’ B (Gate)]
    C -->|Sigmoid| D[Gate Values 0-1]
    B --> E[Element-wise Multiply]
    D --> E
    E --> F[Filtered Output]
```

---

## ğŸ§© Why in Mixture-of-Depths (MoD) or HRMs?

These models want **efficiency**: not all tokens need heavy compute.

* GLU **scores tokens** â†’ decides which go deeper.
* Saves FLOPs ğŸ’», speeds up inference âš¡, and still keeps accuracy.

Think of it as:

* "VIP tokens" get full processing.
* "Background tokens" just pass quickly.

---

## ğŸ Minimal PyTorch Example

```python
import torch
import torch.nn as nn

class GLU(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.linear = nn.Linear(dim, 2*dim)  # split into A and B

    def forward(self, x):
        a, b = self.linear(x).chunk(2, dim=-1)  # split
        return a * torch.sigmoid(b)  # apply gate
```

Usage in MoD/HRM: this gate decides **if a token goes deeper or not**.

---

## ğŸ“š Links to Learn More

* ğŸ”— [GLU Paper (Dauphin et al., 2017)](https://arxiv.org/abs/1612.08083)
* ğŸ”— [Mixture of Depths (Meta AI, 2023)](https://arxiv.org/abs/2308.14711)
* ğŸ”— [HRMs (Hierarchical Residual Mixtures)](https://arxiv.org/abs/2404.02258)

---

## ğŸ¥ Videos

* [Yannic Kilcher â€” Mixture of Depths Explained](https://www.youtube.com/watch?v=HlXB8YqF6tM)
* [GLU Intuition (fastai lecture clip)](https://www.youtube.com/watch?v=V_xro1bcAuA)

---

âœ… **Simple takeaway**:
GLU = a *smart filter* that helps models like MoD/HRMs **decide which tokens deserve full attention** and which can be skipped.
