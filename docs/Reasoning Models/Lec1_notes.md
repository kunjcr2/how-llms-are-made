# üìö Reasoning-Based Large Language Models ‚Äî Course Overview

## What Is This Course About?

- Learn how to build and understand large language models (LLMs) that can **reason step-by-step**, not just give fast answers.
- Focus on giving LLMs the ability to show their thought process for more trustworthy and useful outputs.

---

## What Will You Learn?

- **The difference between fast (System 1) and slow (System 2) reasoning**
- **Why most AIs only ‚Äúanswer,‚Äù not truly ‚Äúreason‚Äù**
- **How recent models (like DeepSeek R1) actually reason**

---

## Course Structure

This course is divided into four main modules:

1. **Inference Time Compute Scaling**

   - Using techniques like Chain-of-Thought prompting to force LLMs to ‚Äúthink out loud.‚Äù

2. **Pure Reinforcement Learning**

   - Teaching models to reason via reward-based learning.

3. **Supervised Fine-Tuning + RL**

   - Combining both fine-tuning and RL for robust reasoning ability.

4. **Supervised Fine-Tuning and Distillation**

   - Transferring reasoning skills from large to small models using supervised data.

---

## Why Reasoning LLMs Matter

- Makes AI more transparent, trustworthy, and reliable for complex tasks.
- A rapidly growing area in the field of AI and NLP.

---
