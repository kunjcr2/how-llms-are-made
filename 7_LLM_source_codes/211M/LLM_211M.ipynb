{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# List of books to download (title: URL)\n",
        "books = {\n",
        "    \"moby_dick.txt\": \"https://www.gutenberg.org/files/2701/2701-0.txt\",\n",
        "    \"pride_prejudice.txt\": \"https://www.gutenberg.org/files/1342/1342-0.txt\",\n",
        "    \"frankenstein.txt\": \"https://www.gutenberg.org/files/84/84-0.txt\",\n",
        "    \"alice_wonderland.txt\": \"https://www.gutenberg.org/files/11/11-0.txt\",\n",
        "    \"christmas_carol.txt\": \"https://www.gutenberg.org/files/98/98-0.txt\",\n",
        "}\n",
        "\n",
        "# Download and store in `data`\n",
        "data = \"\"\n",
        "\n",
        "for name, url in books.items():\n",
        "    print(f\"Downloading {name}...\")\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        text = response.text.strip()\n",
        "        data += text + \"\\n\\n\"\n",
        "    else:\n",
        "        print(f\"Failed to download {name}\")\n",
        "\n",
        "print(\"\\n✅ Download complete. `data` now contains the combined text of all books.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHybnaI-6i24",
        "outputId": "0db5ecd8-16b9-4f49-a6f2-ca81adbaa3ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading moby_dick.txt...\n",
            "Downloading pride_prejudice.txt...\n",
            "Downloading frankenstein.txt...\n",
            "Downloading alice_wonderland.txt...\n",
            "Downloading christmas_carol.txt...\n",
            "\n",
            "✅ Download complete. `data` now contains the combined text of all books.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqe50lsvju_R"
      },
      "source": [
        "## Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0-wTo87kDIr",
        "outputId": "a3f1f0de-1d3f-4fa0-a0b2-062db3ae1d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M7a4EoGAj1x0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "GPT_CONFIG_211M = {\n",
        "    \"vocab_size\": 50257,  # Vocabulary size\n",
        "    \"context_length\": 512,  # Context length\n",
        "    \"emb_dim\": 810,  # Embedding dimension\n",
        "    \"n_layers\": 18,  # Number of\n",
        "    \"n_heads\": 18,  # Number of attention heads per transformer block\n",
        "    \"drop_rate\": 0.2,  # Dropout rate\n",
        "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
        "}\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrmG9EktXox"
      },
      "source": [
        "## Preprocessing stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qU5zdQ25tZiL"
      },
      "outputs": [],
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            self.input_ids.append(torch.tensor(token_ids[i:i + max_length]))\n",
        "            self.target_ids.append(torch.tensor(token_ids[i + 1: i + max_length + 1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_GMl6DPqtlWU"
      },
      "outputs": [],
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZz0LaT97T66"
      },
      "source": [
        "## Complete transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fq8UX3mu71JT"
      },
      "outputs": [],
      "source": [
        "# Multiheaded attetion mechanism. Dude, this shit was fire !\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length, context_length),diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_token, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    keys = keys.view(b, num_token, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_token, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_token, self.num_heads, self.head_dim)\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "    attn_scores = queries @ keys.transpose(2,3) # we get (..., num_token, num_token)\n",
        "    masked_bool = self.mask.bool()[:num_token, :num_token]\n",
        "    attn_scores.masked_fill(masked_bool, -torch.inf)\n",
        "    attn_scores = attn_scores / keys.shape[-1]**0.5\n",
        "    attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = (attn_weights @ values).transpose(1,2)\n",
        "    context_vec = context_vec.contiguous().view(b, num_token, self.d_out)\n",
        "\n",
        "    return context_vec\n",
        "\n",
        "# We normalize the layer at the last dim with mean near to 0 and variance near to 1\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    # we do +self.eps, to let the var not be 0 and division by 0 SHOULD not be done\n",
        "    norm_x = (x-mean)/torch.sqrt(var + self.eps)\n",
        "\n",
        "    # We use scale and shift for better training and they are trainable also !!!\n",
        "    return self.scale * norm_x + self.shift\n",
        "\n",
        "# GeLU function activation\n",
        "class GeLU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  # Better version of ReLU()\n",
        "  def forward(self, x):\n",
        "    return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2/torch.pi))* (x + 0.044715*x**3)))\n",
        "\n",
        "# The classic feed froward neura network\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    # Feed forward network with GeLU between 2 linear\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
        "        GeLU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gN9ehj4290ac"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    # Dude, no need for the comments here. You already know. It is a transformer block bro !\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out=cfg[\"emb_dim\"],\n",
        "        context_length=cfg[\"context_length\"],\n",
        "        dropout=cfg[\"drop_rate\"],\n",
        "        num_heads=cfg[\"n_heads\"],\n",
        "        qkv_bias=cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    # creating shortcut from x to the first dropout layer\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    # creating shortcut from first dropout to the second dropout\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GAAP_9qrZtV9"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        in_idx = in_idx.long()\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9KNnDC1LF0H"
      },
      "source": [
        "## Generating new Output Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0eNJ7R3LKov"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "\n",
        "  # idx is (batch, n_tokens) array of indices in current context\n",
        "  for _ in range(max_new_tokens):\n",
        "    # If LLM suports only 5 tokens, and the context size is 10, then we only use last 5 toens as context.\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "\n",
        "    # Gettings the predictions\n",
        "    with torch.no_grad():\n",
        "      # Reshape idx_cond to (batch_size, sequence_length, emb_dim)\n",
        "      # idx_cond = idx_cond.unsqueeze(-1).repeat(1 , 1, model.norm1.scale.shape[0]) # Or model.att.d_in to get the embedding dimension\n",
        "      logits = model(idx_cond) # (batch, num_tokens, vocab_size)\n",
        "\n",
        "    # We take the last row. We dont do anything to the batches neither to the last dimension of the vocabularies, but take the last row\n",
        "    logits = logits[:, -1, :] # (batch, vocab_size)\n",
        "\n",
        "    # getting probablities from the logits. We can say something like 50% chances of this, 2% chances of this...\n",
        "    probs = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
        "\n",
        "    # We see the highest value's index\n",
        "    idx_next = torch.argmax(probs, dim=-1, keepdim=True) # (batch, 1)\n",
        "\n",
        "    # Append the predicted token_id generated to the original index\n",
        "    idx = torch.cat((idx, idx_next), dim=1) # (batch, num_tokens+1)\n",
        "\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1GdkXKbJsXXX"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
        "  return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YhYloEr_pK"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWpvLkIuR2pz"
      },
      "source": [
        "## Training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bzhKHuN0spZL"
      },
      "outputs": [],
      "source": [
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(data))\n",
        "train_data = data[:split_idx]\n",
        "val_data = data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "btzrBWhVzYrh"
      },
      "outputs": [],
      "source": [
        "# Caluclates loss for a batch\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "# Caluculates loss for ENTIRE data_loader which calls calc_loss_batch function inside itself\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Esc6y7RSOUCU"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  # basically returns the losses for training and validation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    return calc_loss_loader(train_loader, model, device, eval_iter), calc_loss_loader(val_loader, model, device, eval_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MyCcIghSPyQL"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  # we print out, what the model is generating right now at the end of each epoch. Also, we print 50 items!\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "        model, encoded, 50, context_size\n",
        "    )\n",
        "\n",
        "  decoded = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hecWiYDyNF35"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OzoNhE4bMMnc"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize tracking lists\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n🔁 Starting epoch {epoch+1}\")\n",
        "        model.train()\n",
        "        epoch_improved = False\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "                # Check for validation improvement\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    epoch_improved = True\n",
        "\n",
        "        # Print sample after epoch\n",
        "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "        # If no improvement this epoch, skip rest\n",
        "        if not epoch_improved:\n",
        "            print(f\"⚠️ No val loss improvement in epoch {epoch+1}, skipping to next.\")\n",
        "            continue\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay7EKoDuTzny",
        "outputId": "242e3a17-c454-43ba-cc3b-899fe28e5c7d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Starting epoch 1\n",
            "Ep 1 (Step 000000): Train loss 9.341, Val loss 9.186\n",
            "Ep 1 (Step 000050): Train loss 6.760, Val loss 6.644\n",
            "Ep 1 (Step 000100): Train loss 6.139, Val loss 6.314\n",
            "Ep 1 (Step 000150): Train loss 5.959, Val loss 6.117\n",
            "Ep 1 (Step 000200): Train loss 5.683, Val loss 5.972\n",
            "Ep 1 (Step 000250): Train loss 5.771, Val loss 5.903\n",
            "Ep 1 (Step 000300): Train loss 5.579, Val loss 5.770\n",
            "Ep 1 (Step 000350): Train loss 5.180, Val loss 5.704\n",
            "Ep 1 (Step 000400): Train loss 5.558, Val loss 5.654\n",
            "Ep 1 (Step 000450): Train loss 5.205, Val loss 5.636\n",
            "Ep 1 (Step 000500): Train loss 5.555, Val loss 5.551\n",
            "Ep 1 (Step 000550): Train loss 4.805, Val loss 5.566\n",
            "Ep 1 (Step 000600): Train loss 5.180, Val loss 5.543\n",
            "Ep 1 (Step 000650): Train loss 5.201, Val loss 5.519\n",
            "Ep 1 (Step 000700): Train loss 4.999, Val loss 5.463\n",
            "Ep 1 (Step 000750): Train loss 5.116, Val loss 5.459\n",
            "Ep 1 (Step 000800): Train loss 5.182, Val loss 5.424\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 2\n",
            "Ep 2 (Step 000850): Train loss 5.097, Val loss 5.493\n",
            "Ep 2 (Step 000900): Train loss 5.045, Val loss 5.473\n",
            "Ep 2 (Step 000950): Train loss 4.820, Val loss 5.465\n",
            "Ep 2 (Step 001000): Train loss 4.873, Val loss 5.420\n",
            "Ep 2 (Step 001050): Train loss 5.100, Val loss 5.437\n",
            "Ep 2 (Step 001100): Train loss 4.586, Val loss 5.407\n",
            "Ep 2 (Step 001150): Train loss 5.067, Val loss 5.377\n",
            "Ep 2 (Step 001200): Train loss 4.535, Val loss 5.348\n",
            "Ep 2 (Step 001250): Train loss 4.821, Val loss 5.328\n",
            "Ep 2 (Step 001300): Train loss 4.806, Val loss 5.314\n",
            "Ep 2 (Step 001350): Train loss 4.807, Val loss 5.325\n",
            "Ep 2 (Step 001400): Train loss 4.483, Val loss 5.297\n",
            "Ep 2 (Step 001450): Train loss 4.826, Val loss 5.272\n",
            "Ep 2 (Step 001500): Train loss 5.014, Val loss 5.252\n",
            "Ep 2 (Step 001550): Train loss 4.370, Val loss 5.265\n",
            "Ep 2 (Step 001600): Train loss 5.093, Val loss 5.283\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 3\n",
            "Ep 3 (Step 001650): Train loss 4.328, Val loss 5.337\n",
            "Ep 3 (Step 001700): Train loss 4.679, Val loss 5.303\n",
            "Ep 3 (Step 001750): Train loss 4.635, Val loss 5.288\n",
            "Ep 3 (Step 001800): Train loss 4.360, Val loss 5.292\n",
            "Ep 3 (Step 001850): Train loss 4.596, Val loss 5.273\n",
            "Ep 3 (Step 001900): Train loss 4.661, Val loss 5.242\n",
            "Ep 3 (Step 001950): Train loss 4.694, Val loss 5.246\n",
            "Ep 3 (Step 002000): Train loss 4.442, Val loss 5.263\n",
            "Ep 3 (Step 002050): Train loss 4.783, Val loss 5.248\n",
            "Ep 3 (Step 002100): Train loss 4.671, Val loss 5.182\n",
            "Ep 3 (Step 002150): Train loss 4.444, Val loss 5.231\n",
            "Ep 3 (Step 002200): Train loss 4.857, Val loss 5.214\n",
            "Ep 3 (Step 002250): Train loss 4.597, Val loss 5.175\n",
            "Ep 3 (Step 002300): Train loss 4.604, Val loss 5.183\n",
            "Ep 3 (Step 002350): Train loss 4.595, Val loss 5.189\n",
            "Ep 3 (Step 002400): Train loss 4.689, Val loss 5.161\n",
            "Ep 3 (Step 002450): Train loss 4.695, Val loss 5.198\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 4\n",
            "Ep 4 (Step 002500): Train loss 4.728, Val loss 5.211\n",
            "Ep 4 (Step 002550): Train loss 4.628, Val loss 5.174\n",
            "Ep 4 (Step 002600): Train loss 4.759, Val loss 5.168\n",
            "Ep 4 (Step 002650): Train loss 4.524, Val loss 5.176\n",
            "Ep 4 (Step 002700): Train loss 4.521, Val loss 5.155\n",
            "Ep 4 (Step 002750): Train loss 4.060, Val loss 5.184\n",
            "Ep 4 (Step 002800): Train loss 4.347, Val loss 5.165\n",
            "Ep 4 (Step 002850): Train loss 3.719, Val loss 5.165\n",
            "Ep 4 (Step 002900): Train loss 4.402, Val loss 5.115\n",
            "Ep 4 (Step 002950): Train loss 4.471, Val loss 5.115\n",
            "Ep 4 (Step 003000): Train loss 4.699, Val loss 5.116\n",
            "Ep 4 (Step 003050): Train loss 4.262, Val loss 5.080\n",
            "Ep 4 (Step 003100): Train loss 4.272, Val loss 5.069\n",
            "Ep 4 (Step 003150): Train loss 4.384, Val loss 5.047\n",
            "Ep 4 (Step 003200): Train loss 4.638, Val loss 5.087\n",
            "Ep 4 (Step 003250): Train loss 4.597, Val loss 5.075\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 5\n",
            "Ep 5 (Step 003300): Train loss 4.549, Val loss 5.130\n",
            "Ep 5 (Step 003350): Train loss 4.277, Val loss 5.108\n",
            "Ep 5 (Step 003400): Train loss 4.392, Val loss 5.068\n",
            "Ep 5 (Step 003450): Train loss 4.294, Val loss 5.074\n",
            "Ep 5 (Step 003500): Train loss 4.465, Val loss 5.053\n",
            "Ep 5 (Step 003550): Train loss 4.454, Val loss 5.058\n",
            "Ep 5 (Step 003600): Train loss 4.084, Val loss 5.064\n",
            "Ep 5 (Step 003650): Train loss 4.257, Val loss 5.023\n",
            "Ep 5 (Step 003700): Train loss 4.329, Val loss 5.040\n",
            "Ep 5 (Step 003750): Train loss 4.482, Val loss 5.037\n",
            "Ep 5 (Step 003800): Train loss 4.327, Val loss 5.066\n",
            "Ep 5 (Step 003850): Train loss 4.429, Val loss 5.052\n",
            "Ep 5 (Step 003900): Train loss 4.526, Val loss 5.039\n",
            "Ep 5 (Step 003950): Train loss 4.226, Val loss 5.026\n",
            "Ep 5 (Step 004000): Train loss 4.354, Val loss 5.001\n",
            "Ep 5 (Step 004050): Train loss 4.265, Val loss 4.983\n",
            "Ep 5 (Step 004100): Train loss 4.304, Val loss 5.003\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 6\n",
            "Ep 6 (Step 004150): Train loss 4.130, Val loss 5.073\n",
            "Ep 6 (Step 004200): Train loss 4.468, Val loss 5.051\n",
            "Ep 6 (Step 004250): Train loss 4.391, Val loss 5.078\n",
            "Ep 6 (Step 004300): Train loss 4.298, Val loss 5.020\n",
            "Ep 6 (Step 004350): Train loss 4.314, Val loss 5.050\n",
            "Ep 6 (Step 004400): Train loss 4.344, Val loss 5.059\n",
            "Ep 6 (Step 004450): Train loss 4.340, Val loss 5.017\n",
            "Ep 6 (Step 004500): Train loss 3.926, Val loss 4.988\n",
            "Ep 6 (Step 004550): Train loss 4.260, Val loss 5.019\n",
            "Ep 6 (Step 004600): Train loss 4.276, Val loss 5.021\n",
            "Ep 6 (Step 004650): Train loss 4.152, Val loss 4.987\n",
            "Ep 6 (Step 004700): Train loss 4.190, Val loss 4.948\n",
            "Ep 6 (Step 004750): Train loss 4.047, Val loss 4.950\n",
            "Ep 6 (Step 004800): Train loss 4.151, Val loss 4.962\n",
            "Ep 6 (Step 004850): Train loss 4.001, Val loss 4.958\n",
            "Ep 6 (Step 004900): Train loss 4.060, Val loss 4.948\n",
            "I had always                                                   \n",
            "\n",
            "🔁 Starting epoch 7\n",
            "Ep 7 (Step 004950): Train loss 3.727, Val loss 5.015\n",
            "Ep 7 (Step 005000): Train loss 4.045, Val loss 5.006\n",
            "Ep 7 (Step 005050): Train loss 4.143, Val loss 5.016\n",
            "Ep 7 (Step 005100): Train loss 4.055, Val loss 5.053\n",
            "Ep 7 (Step 005150): Train loss 4.096, Val loss 5.015\n",
            "Ep 7 (Step 005200): Train loss 3.884, Val loss 5.023\n",
            "Ep 7 (Step 005250): Train loss 4.094, Val loss 5.015\n",
            "Ep 7 (Step 005300): Train loss 4.049, Val loss 4.995\n",
            "Ep 7 (Step 005350): Train loss 3.717, Val loss 4.989\n",
            "Ep 7 (Step 005400): Train loss 4.111, Val loss 4.988\n",
            "Ep 7 (Step 005450): Train loss 4.256, Val loss 4.976\n",
            "Ep 7 (Step 005500): Train loss 3.880, Val loss 4.969\n",
            "Ep 7 (Step 005550): Train loss 4.282, Val loss 5.023\n",
            "Ep 7 (Step 005600): Train loss 4.003, Val loss 4.970\n",
            "Ep 7 (Step 005650): Train loss 3.995, Val loss 4.974\n",
            "Ep 7 (Step 005700): Train loss 4.062, Val loss 4.959\n",
            "Ep 7 (Step 005750): Train loss 3.972, Val loss 4.954\n",
            "I had always                                                   \n",
            "⚠️ No val loss improvement in epoch 7, skipping to next.\n",
            "\n",
            "🔁 Starting epoch 8\n",
            "Ep 8 (Step 005800): Train loss 3.634, Val loss 5.108\n",
            "Ep 8 (Step 005850): Train loss 4.165, Val loss 5.070\n",
            "Ep 8 (Step 005900): Train loss 3.919, Val loss 5.067\n",
            "Ep 8 (Step 005950): Train loss 3.669, Val loss 5.045\n",
            "Ep 8 (Step 006000): Train loss 3.720, Val loss 5.077\n",
            "Ep 8 (Step 006050): Train loss 4.005, Val loss 5.067\n",
            "Ep 8 (Step 006100): Train loss 3.903, Val loss 5.039\n",
            "Ep 8 (Step 006150): Train loss 3.898, Val loss 5.029\n",
            "Ep 8 (Step 006200): Train loss 4.092, Val loss 5.041\n",
            "Ep 8 (Step 006250): Train loss 3.893, Val loss 5.023\n",
            "Ep 8 (Step 006300): Train loss 3.518, Val loss 4.983\n",
            "Ep 8 (Step 006350): Train loss 3.810, Val loss 4.987\n",
            "Ep 8 (Step 006400): Train loss 4.037, Val loss 4.977\n",
            "Ep 8 (Step 006450): Train loss 3.978, Val loss 5.009\n",
            "Ep 8 (Step 006500): Train loss 3.947, Val loss 4.973\n",
            "Ep 8 (Step 006550): Train loss 3.924, Val loss 4.971\n",
            "I had always                                                   \n",
            "⚠️ No val loss improvement in epoch 8, skipping to next.\n",
            "\n",
            "🔁 Starting epoch 9\n",
            "Ep 9 (Step 006600): Train loss 3.870, Val loss 5.126\n",
            "Ep 9 (Step 006650): Train loss 3.431, Val loss 5.068\n",
            "Ep 9 (Step 006700): Train loss 3.881, Val loss 5.061\n",
            "Ep 9 (Step 006750): Train loss 3.612, Val loss 5.076\n",
            "Ep 9 (Step 006800): Train loss 3.680, Val loss 5.108\n",
            "Ep 9 (Step 006850): Train loss 3.537, Val loss 5.087\n",
            "Ep 9 (Step 006900): Train loss 3.487, Val loss 5.082\n",
            "Ep 9 (Step 006950): Train loss 3.668, Val loss 5.072\n",
            "Ep 9 (Step 007000): Train loss 3.647, Val loss 5.056\n",
            "Ep 9 (Step 007050): Train loss 3.434, Val loss 5.069\n",
            "Ep 9 (Step 007100): Train loss 3.606, Val loss 5.058\n",
            "Ep 9 (Step 007150): Train loss 3.621, Val loss 5.009\n",
            "Ep 9 (Step 007200): Train loss 3.618, Val loss 5.004\n",
            "Ep 9 (Step 007250): Train loss 3.790, Val loss 4.995\n",
            "Ep 9 (Step 007300): Train loss 3.762, Val loss 5.000\n",
            "Ep 9 (Step 007350): Train loss 3.743, Val loss 5.014\n",
            "I had always                                                   \n",
            "⚠️ No val loss improvement in epoch 9, skipping to next.\n",
            "\n",
            "🔁 Starting epoch 10\n",
            "Ep 10 (Step 007400): Train loss 3.601, Val loss 5.027\n",
            "Ep 10 (Step 007450): Train loss 3.557, Val loss 5.067\n",
            "Ep 10 (Step 007500): Train loss 3.587, Val loss 5.125\n",
            "Ep 10 (Step 007550): Train loss 3.612, Val loss 5.107\n",
            "Ep 10 (Step 007600): Train loss 3.510, Val loss 5.114\n",
            "Ep 10 (Step 007650): Train loss 3.456, Val loss 5.089\n",
            "Ep 10 (Step 007700): Train loss 3.511, Val loss 5.077\n",
            "Ep 10 (Step 007750): Train loss 3.819, Val loss 5.131\n",
            "Ep 10 (Step 007800): Train loss 3.588, Val loss 5.107\n",
            "Ep 10 (Step 007850): Train loss 3.545, Val loss 5.070\n",
            "Ep 10 (Step 007900): Train loss 3.478, Val loss 5.049\n",
            "Ep 10 (Step 007950): Train loss 3.283, Val loss 5.050\n",
            "Ep 10 (Step 008000): Train loss 3.553, Val loss 5.018\n",
            "Ep 10 (Step 008050): Train loss 3.533, Val loss 5.025\n",
            "Ep 10 (Step 008100): Train loss 3.513, Val loss 5.023\n",
            "Ep 10 (Step 008150): Train loss 3.380, Val loss 4.975\n",
            "Ep 10 (Step 008200): Train loss 3.367, Val loss 4.966\n",
            "I had always                                                   \n",
            "⚠️ No val loss improvement in epoch 10, skipping to next.\n",
            "Training completed in 77.71 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    start_context=\"I had always \", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (256,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZBPIHhoa5Ht",
        "outputId": "0ef1d48b-5ae5-452b-f232-8a5ac6e6c959"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         Embedding-1             [-1, 256, 810]      40,708,170\n",
            "         Embedding-2                  [-1, 810]         414,720\n",
            "           Dropout-3             [-1, 256, 810]               0\n",
            "         LayerNorm-4             [-1, 256, 810]               0\n",
            "            Linear-5             [-1, 256, 810]         656,100\n",
            "            Linear-6             [-1, 256, 810]         656,100\n",
            "            Linear-7             [-1, 256, 810]         656,100\n",
            "           Dropout-8         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-9             [-1, 256, 810]               0\n",
            "          Dropout-10             [-1, 256, 810]               0\n",
            "        LayerNorm-11             [-1, 256, 810]               0\n",
            "           Linear-12            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-13            [-1, 256, 3240]               0\n",
            "           Linear-14             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-15             [-1, 256, 810]               0\n",
            "          Dropout-16             [-1, 256, 810]               0\n",
            " TransformerBlock-17             [-1, 256, 810]               0\n",
            "        LayerNorm-18             [-1, 256, 810]               0\n",
            "           Linear-19             [-1, 256, 810]         656,100\n",
            "           Linear-20             [-1, 256, 810]         656,100\n",
            "           Linear-21             [-1, 256, 810]         656,100\n",
            "          Dropout-22         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-23             [-1, 256, 810]               0\n",
            "          Dropout-24             [-1, 256, 810]               0\n",
            "        LayerNorm-25             [-1, 256, 810]               0\n",
            "           Linear-26            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-27            [-1, 256, 3240]               0\n",
            "           Linear-28             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-29             [-1, 256, 810]               0\n",
            "          Dropout-30             [-1, 256, 810]               0\n",
            " TransformerBlock-31             [-1, 256, 810]               0\n",
            "        LayerNorm-32             [-1, 256, 810]               0\n",
            "           Linear-33             [-1, 256, 810]         656,100\n",
            "           Linear-34             [-1, 256, 810]         656,100\n",
            "           Linear-35             [-1, 256, 810]         656,100\n",
            "          Dropout-36         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-37             [-1, 256, 810]               0\n",
            "          Dropout-38             [-1, 256, 810]               0\n",
            "        LayerNorm-39             [-1, 256, 810]               0\n",
            "           Linear-40            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-41            [-1, 256, 3240]               0\n",
            "           Linear-42             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-43             [-1, 256, 810]               0\n",
            "          Dropout-44             [-1, 256, 810]               0\n",
            " TransformerBlock-45             [-1, 256, 810]               0\n",
            "        LayerNorm-46             [-1, 256, 810]               0\n",
            "           Linear-47             [-1, 256, 810]         656,100\n",
            "           Linear-48             [-1, 256, 810]         656,100\n",
            "           Linear-49             [-1, 256, 810]         656,100\n",
            "          Dropout-50         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-51             [-1, 256, 810]               0\n",
            "          Dropout-52             [-1, 256, 810]               0\n",
            "        LayerNorm-53             [-1, 256, 810]               0\n",
            "           Linear-54            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-55            [-1, 256, 3240]               0\n",
            "           Linear-56             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-57             [-1, 256, 810]               0\n",
            "          Dropout-58             [-1, 256, 810]               0\n",
            " TransformerBlock-59             [-1, 256, 810]               0\n",
            "        LayerNorm-60             [-1, 256, 810]               0\n",
            "           Linear-61             [-1, 256, 810]         656,100\n",
            "           Linear-62             [-1, 256, 810]         656,100\n",
            "           Linear-63             [-1, 256, 810]         656,100\n",
            "          Dropout-64         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-65             [-1, 256, 810]               0\n",
            "          Dropout-66             [-1, 256, 810]               0\n",
            "        LayerNorm-67             [-1, 256, 810]               0\n",
            "           Linear-68            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-69            [-1, 256, 3240]               0\n",
            "           Linear-70             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-71             [-1, 256, 810]               0\n",
            "          Dropout-72             [-1, 256, 810]               0\n",
            " TransformerBlock-73             [-1, 256, 810]               0\n",
            "        LayerNorm-74             [-1, 256, 810]               0\n",
            "           Linear-75             [-1, 256, 810]         656,100\n",
            "           Linear-76             [-1, 256, 810]         656,100\n",
            "           Linear-77             [-1, 256, 810]         656,100\n",
            "          Dropout-78         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-79             [-1, 256, 810]               0\n",
            "          Dropout-80             [-1, 256, 810]               0\n",
            "        LayerNorm-81             [-1, 256, 810]               0\n",
            "           Linear-82            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-83            [-1, 256, 3240]               0\n",
            "           Linear-84             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-85             [-1, 256, 810]               0\n",
            "          Dropout-86             [-1, 256, 810]               0\n",
            " TransformerBlock-87             [-1, 256, 810]               0\n",
            "        LayerNorm-88             [-1, 256, 810]               0\n",
            "           Linear-89             [-1, 256, 810]         656,100\n",
            "           Linear-90             [-1, 256, 810]         656,100\n",
            "           Linear-91             [-1, 256, 810]         656,100\n",
            "          Dropout-92         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-93             [-1, 256, 810]               0\n",
            "          Dropout-94             [-1, 256, 810]               0\n",
            "        LayerNorm-95             [-1, 256, 810]               0\n",
            "           Linear-96            [-1, 256, 3240]       2,627,640\n",
            "             GeLU-97            [-1, 256, 3240]               0\n",
            "           Linear-98             [-1, 256, 810]       2,625,210\n",
            "      FeedForward-99             [-1, 256, 810]               0\n",
            "         Dropout-100             [-1, 256, 810]               0\n",
            "TransformerBlock-101             [-1, 256, 810]               0\n",
            "       LayerNorm-102             [-1, 256, 810]               0\n",
            "          Linear-103             [-1, 256, 810]         656,100\n",
            "          Linear-104             [-1, 256, 810]         656,100\n",
            "          Linear-105             [-1, 256, 810]         656,100\n",
            "         Dropout-106         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-107             [-1, 256, 810]               0\n",
            "         Dropout-108             [-1, 256, 810]               0\n",
            "       LayerNorm-109             [-1, 256, 810]               0\n",
            "          Linear-110            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-111            [-1, 256, 3240]               0\n",
            "          Linear-112             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-113             [-1, 256, 810]               0\n",
            "         Dropout-114             [-1, 256, 810]               0\n",
            "TransformerBlock-115             [-1, 256, 810]               0\n",
            "       LayerNorm-116             [-1, 256, 810]               0\n",
            "          Linear-117             [-1, 256, 810]         656,100\n",
            "          Linear-118             [-1, 256, 810]         656,100\n",
            "          Linear-119             [-1, 256, 810]         656,100\n",
            "         Dropout-120         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-121             [-1, 256, 810]               0\n",
            "         Dropout-122             [-1, 256, 810]               0\n",
            "       LayerNorm-123             [-1, 256, 810]               0\n",
            "          Linear-124            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-125            [-1, 256, 3240]               0\n",
            "          Linear-126             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-127             [-1, 256, 810]               0\n",
            "         Dropout-128             [-1, 256, 810]               0\n",
            "TransformerBlock-129             [-1, 256, 810]               0\n",
            "       LayerNorm-130             [-1, 256, 810]               0\n",
            "          Linear-131             [-1, 256, 810]         656,100\n",
            "          Linear-132             [-1, 256, 810]         656,100\n",
            "          Linear-133             [-1, 256, 810]         656,100\n",
            "         Dropout-134         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-135             [-1, 256, 810]               0\n",
            "         Dropout-136             [-1, 256, 810]               0\n",
            "       LayerNorm-137             [-1, 256, 810]               0\n",
            "          Linear-138            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-139            [-1, 256, 3240]               0\n",
            "          Linear-140             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-141             [-1, 256, 810]               0\n",
            "         Dropout-142             [-1, 256, 810]               0\n",
            "TransformerBlock-143             [-1, 256, 810]               0\n",
            "       LayerNorm-144             [-1, 256, 810]               0\n",
            "          Linear-145             [-1, 256, 810]         656,100\n",
            "          Linear-146             [-1, 256, 810]         656,100\n",
            "          Linear-147             [-1, 256, 810]         656,100\n",
            "         Dropout-148         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-149             [-1, 256, 810]               0\n",
            "         Dropout-150             [-1, 256, 810]               0\n",
            "       LayerNorm-151             [-1, 256, 810]               0\n",
            "          Linear-152            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-153            [-1, 256, 3240]               0\n",
            "          Linear-154             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-155             [-1, 256, 810]               0\n",
            "         Dropout-156             [-1, 256, 810]               0\n",
            "TransformerBlock-157             [-1, 256, 810]               0\n",
            "       LayerNorm-158             [-1, 256, 810]               0\n",
            "          Linear-159             [-1, 256, 810]         656,100\n",
            "          Linear-160             [-1, 256, 810]         656,100\n",
            "          Linear-161             [-1, 256, 810]         656,100\n",
            "         Dropout-162         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-163             [-1, 256, 810]               0\n",
            "         Dropout-164             [-1, 256, 810]               0\n",
            "       LayerNorm-165             [-1, 256, 810]               0\n",
            "          Linear-166            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-167            [-1, 256, 3240]               0\n",
            "          Linear-168             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-169             [-1, 256, 810]               0\n",
            "         Dropout-170             [-1, 256, 810]               0\n",
            "TransformerBlock-171             [-1, 256, 810]               0\n",
            "       LayerNorm-172             [-1, 256, 810]               0\n",
            "          Linear-173             [-1, 256, 810]         656,100\n",
            "          Linear-174             [-1, 256, 810]         656,100\n",
            "          Linear-175             [-1, 256, 810]         656,100\n",
            "         Dropout-176         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-177             [-1, 256, 810]               0\n",
            "         Dropout-178             [-1, 256, 810]               0\n",
            "       LayerNorm-179             [-1, 256, 810]               0\n",
            "          Linear-180            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-181            [-1, 256, 3240]               0\n",
            "          Linear-182             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-183             [-1, 256, 810]               0\n",
            "         Dropout-184             [-1, 256, 810]               0\n",
            "TransformerBlock-185             [-1, 256, 810]               0\n",
            "       LayerNorm-186             [-1, 256, 810]               0\n",
            "          Linear-187             [-1, 256, 810]         656,100\n",
            "          Linear-188             [-1, 256, 810]         656,100\n",
            "          Linear-189             [-1, 256, 810]         656,100\n",
            "         Dropout-190         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-191             [-1, 256, 810]               0\n",
            "         Dropout-192             [-1, 256, 810]               0\n",
            "       LayerNorm-193             [-1, 256, 810]               0\n",
            "          Linear-194            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-195            [-1, 256, 3240]               0\n",
            "          Linear-196             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-197             [-1, 256, 810]               0\n",
            "         Dropout-198             [-1, 256, 810]               0\n",
            "TransformerBlock-199             [-1, 256, 810]               0\n",
            "       LayerNorm-200             [-1, 256, 810]               0\n",
            "          Linear-201             [-1, 256, 810]         656,100\n",
            "          Linear-202             [-1, 256, 810]         656,100\n",
            "          Linear-203             [-1, 256, 810]         656,100\n",
            "         Dropout-204         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-205             [-1, 256, 810]               0\n",
            "         Dropout-206             [-1, 256, 810]               0\n",
            "       LayerNorm-207             [-1, 256, 810]               0\n",
            "          Linear-208            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-209            [-1, 256, 3240]               0\n",
            "          Linear-210             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-211             [-1, 256, 810]               0\n",
            "         Dropout-212             [-1, 256, 810]               0\n",
            "TransformerBlock-213             [-1, 256, 810]               0\n",
            "       LayerNorm-214             [-1, 256, 810]               0\n",
            "          Linear-215             [-1, 256, 810]         656,100\n",
            "          Linear-216             [-1, 256, 810]         656,100\n",
            "          Linear-217             [-1, 256, 810]         656,100\n",
            "         Dropout-218         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-219             [-1, 256, 810]               0\n",
            "         Dropout-220             [-1, 256, 810]               0\n",
            "       LayerNorm-221             [-1, 256, 810]               0\n",
            "          Linear-222            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-223            [-1, 256, 3240]               0\n",
            "          Linear-224             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-225             [-1, 256, 810]               0\n",
            "         Dropout-226             [-1, 256, 810]               0\n",
            "TransformerBlock-227             [-1, 256, 810]               0\n",
            "       LayerNorm-228             [-1, 256, 810]               0\n",
            "          Linear-229             [-1, 256, 810]         656,100\n",
            "          Linear-230             [-1, 256, 810]         656,100\n",
            "          Linear-231             [-1, 256, 810]         656,100\n",
            "         Dropout-232         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-233             [-1, 256, 810]               0\n",
            "         Dropout-234             [-1, 256, 810]               0\n",
            "       LayerNorm-235             [-1, 256, 810]               0\n",
            "          Linear-236            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-237            [-1, 256, 3240]               0\n",
            "          Linear-238             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-239             [-1, 256, 810]               0\n",
            "         Dropout-240             [-1, 256, 810]               0\n",
            "TransformerBlock-241             [-1, 256, 810]               0\n",
            "       LayerNorm-242             [-1, 256, 810]               0\n",
            "          Linear-243             [-1, 256, 810]         656,100\n",
            "          Linear-244             [-1, 256, 810]         656,100\n",
            "          Linear-245             [-1, 256, 810]         656,100\n",
            "         Dropout-246         [-1, 18, 256, 256]               0\n",
            "MultiHeadAttention-247             [-1, 256, 810]               0\n",
            "         Dropout-248             [-1, 256, 810]               0\n",
            "       LayerNorm-249             [-1, 256, 810]               0\n",
            "          Linear-250            [-1, 256, 3240]       2,627,640\n",
            "            GeLU-251            [-1, 256, 3240]               0\n",
            "          Linear-252             [-1, 256, 810]       2,625,210\n",
            "     FeedForward-253             [-1, 256, 810]               0\n",
            "         Dropout-254             [-1, 256, 810]               0\n",
            "TransformerBlock-255             [-1, 256, 810]               0\n",
            "       LayerNorm-256             [-1, 256, 810]               0\n",
            "          Linear-257           [-1, 256, 50257]      40,708,170\n",
            "================================================================\n",
            "Total params: 211,811,760\n",
            "Trainable params: 211,811,760\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 805.97\n",
            "Params size (MB): 808.00\n",
            "Estimated Total Size (MB): 1613.96\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"GPT2_211M.pth\")"
      ],
      "metadata": {
        "id": "pm9XJP0zatQu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids_to_text(\n",
        "    model(\n",
        "        text_to_token_ids(\n",
        "            \"hello, i am \",\n",
        "            tokenizer\n",
        "        )\n",
        "    ),\n",
        "    tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YOEfMgv6bZij",
        "outputId": "54a9a353-ed06-438b-e7c8-afbbf0cc04e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-18f77ca6c075>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m token_ids_to_text(\n\u001b[0;32m----> 2\u001b[0;31m     model(\n\u001b[0m\u001b[1;32m      3\u001b[0m         text_to_token_ids(\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m\"hello, i am \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-43e7a04ddc01>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0min_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtok_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpos_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embeds\u001b[0m  \u001b[0;31m# Shape [batch_size, num_tokens, emb_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post training stuff"
      ],
      "metadata": {
        "id": "Rdf6MWEnwP48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also use torch.multinomial() instead of torch.argmax().\n",
        "\n",
        "And then we use torch.topk() for doing top-k sampling plus the temprature scaling"
      ],
      "metadata": {
        "id": "MCm-LO_Swupn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temprature=0.0, top_k=None, eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "\n",
        "    # compressing idx to the context_size and basically taking last 4 tokens\n",
        "    idx = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      # we just need vocab size and batch thing, no need to keep track of num_tokens\n",
        "      logits = model(idx)[:, -1, :]\n",
        "\n",
        "    if top_k is not None:\n",
        "      # We take top k elements with highests logits score\n",
        "      top_logits = torch.topk(logits, top_k)\n",
        "\n",
        "      # Getting minimum value among three\n",
        "      min_val = top_logits[:, -1]\n",
        "\n",
        "      # replacing everything in logits to -infinity that is less than min_val\n",
        "      logits = torch.where(\n",
        "          condition=logits<min_val,\n",
        "          torch.tensor(float(-inf)).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "\n",
        "    # If temprature is above 0, we do temprature scaling\n",
        "    if temprature > 0.0:\n",
        "      # More temprature, high creativity. Less temprature, low creativity.\n",
        "      logits = logits / temprature\n",
        "      # applying softmax\n",
        "      probs =  torch.softmax(logits, dim=-1)\n",
        "\n",
        "      # Using multinomial, so that we pick randomly from the top k samples\n",
        "      idx_next = torch.multinomial(probs, num_sample=1)\n",
        "    else:\n",
        "      # If no temprature, we use argmax\n",
        "      idx_next = torch.argmax(logits, dim=-1, keep_dim=True)\n",
        "\n",
        "    # If we see end of sequence token, we stop early\n",
        "    if idx_next==eos_id:\n",
        "      break\n",
        "\n",
        "    # and we concat the new token, to the older sentence and move back or out of the for loop\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "F4ORTwgwQHnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}